<!DOCTYPE html>
<html  lang="ko">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.1" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Colab에서 PyTorch 모델 TPU로 학습하기 - Beomi&#39;s Tech blog</title>








<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89162642-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-89162642-1');
</script>

    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    


<link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="is-2-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                Beomi&#39;s Tech Blog
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="https://junbuml.ee">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="카탈로그" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main">
<div class="card">
    
    <div class="card-image">
        <span  class="image is-7by1">
            <img class="thumbnail" src="https://d1sr4ybm5bj1wl.cloudfront.net/img/2020-02-24-031332.jpg" alt="Colab에서 PyTorch 모델 TPU로 학습하기">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-02-23T15:00:00.000Z">2020-02-24</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/DevEnv/">DevEnv</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/DevEnv/DataScience/">DataScience</a>
                </div>
                
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                Colab에서 PyTorch 모델 TPU로 학습하기
            
        </h1>
        <div class="content">
            <p>딥러닝 모델을 학습시키다 보면 항상 vram의 압박에 시달리게 된다. 특히 최근 막대한 크기의 모델들이 등장해 이런 압박은 더 심해지기도 한다.</p>
<p>한편, 일반 사용자용 그래픽 카드 중 최상위인 <code>Nvidia 2080ti</code>조차도 vram이 겨우 11GB밖에 되지 않아 거대한 모델을 Fine-tuning 하는 것조차 굉장히 작은 배치사이즈로 학습시켜야 한다.</p>
<p>Google Colab에서 제공하는 TPU는 <code>tpu v3-8</code> 모델로 총 128GB의 메모리를 가지고 있어, 상대적으로 큰 모델과 배치사이즈를 이용해 학습할 수 있다. (<code>tpu v3</code> 하나는 16GB의 HBM 메모리를 가지고 있고, <code>tpu v3-8</code>은 8개의 코어로 총 128GB의 메모리를 가진다.)</p>
<p>PyTorch에서는 <a href="https://github.com/pytorch/xla">Pytorch/XLA</a> 프로젝트를 통해 PyTorch에서도 TPU를 통한 학습을 할 수 있도록 컴파일러를 제공하고 있고, colab에 해당 패키지를 설치하면 TPU를 곧바로 사용할 수 있다.</p>
<blockquote>
<p><strong>NOTE:</strong> 이번 글은 아래 공식 튜토리얼의 내용을 따라갑니다.</p>
<p><a href="https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/single-core-alexnet-fashion-mnist.ipynb">공식 Tutorial: PyTorch on Cloud TPUs: Single Core Training AlexNet on Fashion MNIST</a></p>
<p>(단 내용의 100%를 담는 대신, 기존 PyTorch와 동일한 부분은 제외함)</p>
</blockquote>
<a id="more"></a>

<h2 id="PyTorch-XLA-설치하기"><a href="#PyTorch-XLA-설치하기" class="headerlink" title="PyTorch/XLA 설치하기"></a>PyTorch/XLA 설치하기</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">VERSION = "20200220"</span><br><span class="line">!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py</span><br><span class="line">!python pytorch-xla-env-setup.py --version $VERSION</span><br></pre></td></tr></table></figure>

<p><code>PyTorch/XLA</code> 패키지는 Github에서 설치 스크립트를 받아 설치할 수 있다.</p>
<blockquote>
<p>글 쓰는 날짜 2020/02/24에는 <code>20200220</code>이 최신버전이다.</p>
</blockquote>
<p>colab에서 설치를 진행하면 <code>torch-1.4.0</code> 을 <code>torch-1.5.0a0</code> 버전으로, <code>torchvision-0.5.0</code> 을 <code>0.6.0a0</code> 로 업데이트한다. 이와 함께 설치하는 <code>torch-xla</code> 패키지가 메인 패키지가 된다.</p>
<h2 id="데이터셋-준비하기"><a href="#데이터셋-준비하기" class="headerlink" title="데이터셋 준비하기"></a>데이터셋 준비하기</h2><p>데이터셋을 다루는 방법은 기존 PyTorch에서 사용하던 방법과 동일하다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"></span><br><span class="line">raw_dataset = datasets.FashionMNIST(</span><br><span class="line">  os.path.join(<span class="string">"/tmp/fashionmnist"</span>),</span><br><span class="line">  train=<span class="literal">True</span>,</span><br><span class="line">  download=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><code>torchvision.datasets</code> 를 통해 FashionMNIST를 받을 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># See https://pytorch.org/docs/stable/torchvision/models.html for normalization</span></span><br><span class="line"><span class="comment"># Pre-trained TorchVision models expect RGB (3 x H x W) images</span></span><br><span class="line"><span class="comment"># H and W should be &gt;= 224</span></span><br><span class="line"><span class="comment"># Loaded into [0, 1] and normalized as follows:</span></span><br><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                                 std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">to_rgb = transforms.Lambda(<span class="keyword">lambda</span> image: image.convert(<span class="string">'RGB'</span>))</span><br><span class="line">resize = transforms.Resize((<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">my_transform = transforms.Compose([resize, to_rgb, transforms.ToTensor(), normalize])</span><br></pre></td></tr></table></figure>

<p><code>torchvision.transforms</code>를 통해 데이터셋을 이미지넷 기반으로 Normalize하고 &amp; RGB &amp; 244x244 사이즈로 리사이징 하는 처리를 해줄 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = datasets.FashionMNIST(</span><br><span class="line">  os.path.join(<span class="string">"/tmp/fashionmnist"</span>),</span><br><span class="line">  train=<span class="literal">True</span>,</span><br><span class="line">  download=<span class="literal">True</span>,</span><br><span class="line">  transform=my_transform)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.FashionMNIST(</span><br><span class="line">  os.path.join(<span class="string">"/tmp/fashionmnist"</span>),</span><br><span class="line">  train=<span class="literal">False</span>,</span><br><span class="line">  download=<span class="literal">True</span>,</span><br><span class="line">  transform=my_transform)</span><br></pre></td></tr></table></figure>

<p>Dataset을 load할 때 <code>transform</code> 인자로 전달해주면 위 처리가 모두 함께 진행된다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_sampler = torch.utils.data.RandomSampler(train_dataset)</span><br><span class="line">test_sampler = torch.utils.data.RandomSampler(test_dataset)</span><br></pre></td></tr></table></figure>

<p>이후 Sampler를 통해 순서를 적절히 섞어준다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">  train_dataset,</span><br><span class="line">  batch_size=batch_size,</span><br><span class="line">  sampler=train_sampler)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">  test_dataset,</span><br><span class="line">  batch_size=batch_size,</span><br><span class="line">  sampler=test_sampler)</span><br></pre></td></tr></table></figure>

<p>위와 같이 DataLoader를 통해 데이터셋을 <code>batch_size</code>로 잘라 Iterable한 객체로 바꿔준다.</p>
<blockquote>
<p>보다 자세한 Dataset, Sampler, DataLoader에 대한 정보는 아래 링크를 참고해보자.</p>
<p><a href="https://hulk89.github.io/pytorch/2019/09/30/pytorch_dataset/">[링크] pytorch dataset 정리 | Hulk의 개인 공부용 블로그</a></p>
</blockquote>
<h2 id="중요-torch-xla-패키지로-Device-지정하기"><a href="#중요-torch-xla-패키지로-Device-지정하기" class="headerlink" title="[중요!] torch-xla 패키지로 Device 지정하기"></a>[중요!] torch-xla 패키지로 Device 지정하기</h2><p>PyTorch에서는 <code>.to(device)</code> 문법을 통해 텐서 변수들과 모델들을 GPU와 같은 <code>device</code>에 올릴 수 있다.</p>
<p>TPU에 올리기 위해서는 <code>torch_xla</code> 에서 제공하는 <code>xm.xla_device()</code> 를 통해 PyTorch에 호환되는 <code>device</code> 를 지정할 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch_xla</span><br><span class="line"><span class="keyword">import</span> torch_xla.core.xla_model <span class="keyword">as</span> xm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creates AlexNet for 10 classes</span></span><br><span class="line">net = torchvision.models.alexnet(num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Acquires the default Cloud TPU core and moves the model to it</span></span><br><span class="line">device = xm.xla_device()</span><br><span class="line">net = net.to(device)</span><br></pre></td></tr></table></figure>

<h2 id="TPU로-PyTorch-딥러닝-모델-학습시키기"><a href="#TPU로-PyTorch-딥러닝-모델-학습시키기" class="headerlink" title="TPU로 PyTorch 딥러닝 모델 학습시키기"></a>TPU로 PyTorch 딥러닝 모델 학습시키기</h2><p>DataLoader와 Transforms를 이용해 데이터를 증폭시키고 적절한 수준의 이미지로 변환시키는 과정은 기존의 PyTorch 코드와 완전히 동일하다.</p>
<p>또한, loss function와 optimizer도 <code>torch.nn</code>와 <code>torch.optim</code>에서 사용하는 것 그대로 사용할 수 있다.</p>
<p>그리고 나머지 Training 과정의 코드도 거의 99% 동일하지만 <code>.to(device)</code> 의 device가 TPU라는 점만이 차이가 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Note: this will take 4-5 minutes to run.</span></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensures network is in train mode</span></span><br><span class="line">net.train()</span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">  <span class="keyword">for</span> data, targets <span class="keyword">in</span> iter(train_loader):</span><br><span class="line">    <span class="comment"># Sends data and targets to device</span></span><br><span class="line">    data = data.to(device)</span><br><span class="line">    targets = targets.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Acquires the network's best guesses at each class</span></span><br><span class="line">    results = net(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Computes loss</span></span><br><span class="line">    loss = loss_fn(results, targets)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Updates model</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    xm.optimizer_step(optimizer, barrier=<span class="literal">True</span>)  <span class="comment"># 이부분이 TPU 쓸때 필요한 코드!!</span></span><br><span class="line"></span><br><span class="line">elapsed_time = time.time() - start_time</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Spent "</span>, elapsed_time, <span class="string">" seconds training for "</span>, num_epochs, <span class="string">" epoch(s) on a single core."</span>)</span><br></pre></td></tr></table></figure>

<p>위 코드 중 25번째 줄의 <code>xm.optimizer_step(optimizer, barrier=True)</code> 부분이 TPU를 사용하기 위한 코드이다. (GPU 코드에 겨우 한줄 추가!)</p>
<h2 id="TPU-코어-FULL-활용하기"><a href="#TPU-코어-FULL-활용하기" class="headerlink" title="TPU 코어 FULL 활용하기"></a>TPU 코어 FULL 활용하기</h2><p>앞서 다룬 과정에서는 TPU 8core 중 1core만을 사용한다. 한편, TPU 1개에 들어있는 8개의 코어 전체를 사용하면 보다 빠른 학습이 가능하다.</p>
<blockquote>
<p>아래 코드는 PyTorch/XLA의 공식 튜토리얼을 참고합니다.</p>
<p><a href="https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/multi-core-alexnet-fashion-mnist.ipynb">공식 Tutorial: PyTorch on Cloud TPUs: MultiCore Training AlexNet on Fashion MNIST</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_xla</span><br><span class="line"><span class="keyword">import</span> torch_xla.core.xla_model <span class="keyword">as</span> xm</span><br><span class="line"><span class="keyword">import</span> torch_xla.distributed.xla_multiprocessing <span class="keyword">as</span> xmp</span><br><span class="line"></span><br><span class="line"><span class="comment"># "Map function": acquires a corresponding Cloud TPU core, creates a tensor on it,</span></span><br><span class="line"><span class="comment"># and prints its core</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">simple_map_fn</span><span class="params">(index, flags)</span>:</span></span><br><span class="line">  <span class="comment"># Sets a common random seed - both for initialization and ensuring graph is the same</span></span><br><span class="line">  torch.manual_seed(<span class="number">1234</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Acquires the (unique) Cloud TPU core corresponding to this process's index</span></span><br><span class="line">  device = xm.xla_device()  </span><br><span class="line"></span><br><span class="line">  <span class="comment"># Creates a tensor on this process's device</span></span><br><span class="line">  t = torch.randn((<span class="number">2</span>, <span class="number">2</span>), device=device)</span><br><span class="line"></span><br><span class="line">  print(<span class="string">"Process"</span>, index ,<span class="string">"is using"</span>, xm.xla_real_devices([str(device)])[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Spawns eight of the map functions, one for each of the eight cores on</span></span><br><span class="line"><span class="comment"># the Cloud TPU</span></span><br><span class="line">flags = &#123;&#125;</span><br><span class="line"><span class="comment"># Note: Colab only supports start_method='fork'</span></span><br><span class="line">xmp.spawn(simple_map_fn, args=(flags,), nprocs=<span class="number">8</span>, start_method=<span class="string">'fork'</span>)</span><br></pre></td></tr></table></figure>

<p>TPU 여러 코어를 사용하기 위해서는 <code>torch_xla.distributed.xla_multiprocessing</code> 을 통해 프로세스를 N개 띄우는 방식으로 진행한다.</p>
<p>단, 앞서 진행한 코드는 model과 data 로드 부분이 모두 각자의 코드로 나와 Colab 인스턴스의 CPU/Ram에서 진행되어 코드 내의 변수를 <code>.to(device)</code> 를 사용해 GPU나 TPU로 보낼 수 있지만, TPU의 여러 코어를 사용할때는 하나의 함수 내에 model과 data 모두를 넣고 진행해야 한다. </p>
<p>아래와 같이 <code>map_fn</code> 을 만들어서 PyTorch 학습/평가를 위한 부분을 넣어준다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch_xla.distributed.parallel_loader <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_fn</span><span class="params">(index, flags)</span>:</span></span><br><span class="line">  torch.manual_seed(flags[<span class="string">'seed'</span>])</span><br><span class="line">  device = xm.xla_device()  </span><br><span class="line">  dataset_path = os.path.join(<span class="string">"/tmp/fashionmnist"</span>, str(xm.get_ordinal()))</span><br><span class="line">  normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                                  std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">  to_rgb = transforms.Lambda(<span class="keyword">lambda</span> image: image.convert(<span class="string">'RGB'</span>))</span><br><span class="line">  resize = transforms.Resize((<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">  my_transform = transforms.Compose([resize, to_rgb, transforms.ToTensor(), normalize])</span><br><span class="line">  </span><br><span class="line">  train_dataset = datasets.FashionMNIST(</span><br><span class="line">    dataset_path,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=my_transform)</span><br><span class="line"></span><br><span class="line">  test_dataset = datasets.FashionMNIST(</span><br><span class="line">    dataset_path,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=my_transform)</span><br><span class="line">  </span><br><span class="line">  train_sampler = torch.utils.data.distributed.DistributedSampler(</span><br><span class="line">    train_dataset,</span><br><span class="line">    num_replicas=xm.xrt_world_size(),</span><br><span class="line">    rank=xm.get_ordinal(),</span><br><span class="line">    shuffle=<span class="literal">True</span>)</span><br><span class="line">  </span><br><span class="line">  test_sampler = torch.utils.data.distributed.DistributedSampler(</span><br><span class="line">    test_dataset,</span><br><span class="line">    num_replicas=xm.xrt_world_size(),</span><br><span class="line">    rank=xm.get_ordinal(),</span><br><span class="line">    shuffle=<span class="literal">False</span>)</span><br><span class="line">  </span><br><span class="line">  train_loader = torch.utils.data.DataLoader(</span><br><span class="line">      train_dataset,</span><br><span class="line">      batch_size=flags[<span class="string">'batch_size'</span>],</span><br><span class="line">      sampler=train_sampler,</span><br><span class="line">      num_workers=flags[<span class="string">'num_workers'</span>],</span><br><span class="line">      drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  test_loader = torch.utils.data.DataLoader(</span><br><span class="line">      test_dataset,</span><br><span class="line">      batch_size=flags[<span class="string">'batch_size'</span>],</span><br><span class="line">      sampler=test_sampler,</span><br><span class="line">      shuffle=<span class="literal">False</span>,</span><br><span class="line">      num_workers=flags[<span class="string">'num_workers'</span>],</span><br><span class="line">      drop_last=<span class="literal">True</span>)</span><br><span class="line">  </span><br><span class="line">  net = torchvision.models.alexnet(num_classes=<span class="number">10</span>).to(device).train()</span><br><span class="line"></span><br><span class="line">  loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">  optimizer = torch.optim.Adam(net.parameters())</span><br><span class="line"></span><br><span class="line">  train_start = time.time()</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> range(flags[<span class="string">'num_epochs'</span>]):</span><br><span class="line">    para_train_loader = pl.ParallelLoader(train_loader, [device]).per_device_loader(device)</span><br><span class="line">    <span class="keyword">for</span> batch_num, batch <span class="keyword">in</span> enumerate(para_train_loader):</span><br><span class="line">      data, targets = batch </span><br><span class="line"></span><br><span class="line">      output = net(data)</span><br><span class="line"></span><br><span class="line">      loss = loss_fn(output, targets)</span><br><span class="line"></span><br><span class="line">      optimizer.zero_grad()</span><br><span class="line">      loss.backward()</span><br><span class="line"></span><br><span class="line">      xm.optimizer_step(optimizer)  <span class="comment"># ParallelLoader 쓸때는 barrier=True 필요 없음</span></span><br><span class="line"></span><br><span class="line">  elapsed_train_time = time.time() - train_start</span><br><span class="line">  print(<span class="string">"Process"</span>, index, <span class="string">"finished training. Train time was:"</span>, elapsed_train_time) </span><br><span class="line"></span><br><span class="line">  <span class="comment">## Evaluation</span></span><br><span class="line">  <span class="comment"># Sets net to eval and no grad context </span></span><br><span class="line">  net.eval()</span><br><span class="line">  eval_start = time.time()</span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    total_guesses = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    para_train_loader = pl.ParallelLoader(test_loader, [device]).per_device_loader(device)</span><br><span class="line">    <span class="keyword">for</span> batch_num, batch <span class="keyword">in</span> enumerate(para_train_loader):</span><br><span class="line">      data, targets = batch</span><br><span class="line"></span><br><span class="line">      output = net(data)</span><br><span class="line">      best_guesses = torch.argmax(output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      num_correct += torch.eq(targets, best_guesses).sum().item()</span><br><span class="line">      total_guesses += flags[<span class="string">'batch_size'</span>]</span><br><span class="line">  </span><br><span class="line">  elapsed_eval_time = time.time() - eval_start</span><br><span class="line">  print(<span class="string">"Process"</span>, index, <span class="string">"finished evaluation. Evaluation time was:"</span>, elapsed_eval_time)</span><br><span class="line">  print(<span class="string">"Process"</span>, index, <span class="string">"guessed"</span>, num_correct, <span class="string">"of"</span>, total_guesses, <span class="string">"correctly for"</span>, num_correct/total_guesses * <span class="number">100</span>, <span class="string">"% accuracy."</span>)</span><br></pre></td></tr></table></figure>

<p>이전 코드와 다른 부분은 74번째 줄에서 더이상 <code>barrier=True</code> 가 필요하지 않다는 것이다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configures training (and evaluation) parameters</span></span><br><span class="line">flags[<span class="string">'batch_size'</span>] = <span class="number">32</span></span><br><span class="line">flags[<span class="string">'num_workers'</span>] = <span class="number">8</span></span><br><span class="line">flags[<span class="string">'num_epochs'</span>] = <span class="number">1</span></span><br><span class="line">flags[<span class="string">'seed'</span>] = <span class="number">1234</span></span><br><span class="line"></span><br><span class="line">xmp.spawn(map_fn, args=(flags,), nprocs=<span class="number">8</span>, start_method=<span class="string">'fork'</span>)</span><br></pre></td></tr></table></figure>

<p>위에서 만든 함수를 <code>xmp.spawn</code> 함수를 통해 배치사이즈, 워커(코어수=8개), epochs, seed값을 제공해주면 실제 TPU로 해당 코드가 컴파일 되어 전달된 뒤 학습이 진행된다.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><p><a href="https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/single-core-alexnet-fashion-mnist.ipynb">공식 Tutorial: PyTorch on Cloud TPUs: Single Core Training AlexNet on Fashion MNIST</a></p>
</li>
<li><p><a href="https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/multi-core-alexnet-fashion-mnist.ipynb">공식 Tutorial: PyTorch on Cloud TPUs: MultiCore Training AlexNet on Fashion MNIST</a></p>
</li>
<li><p><a href="https://hulk89.github.io/pytorch/2019/09/30/pytorch_dataset/">Hulk의 개인 공부용 블로그: pytorch dataset 정리</a></p>
</li>
</ul>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/colab/" rel="tag">colab</a>, <a class="has-link-grey -link" href="/tags/pytorch/" rel="tag">pytorch</a>, <a class="has-link-grey -link" href="/tags/tpu/" rel="tag">tpu</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2020/02/26/Train-BERT-from-scratch-on-colab-TPU-Tensorflow-ver/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">Colab에서 TPU로 BERT 처음부터 학습시키기 - Tensorflow/Google ver.</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2020/02/13/AWS-SSM-with-Bastion/">
                <span class="level-item">AWS SSM로 VPN없이 Private 자원 접근하기</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right ">
    
        

    <div class="card widget" id="toc">
        <div class="card-content">
            <div class="menu">
                <h3 class="menu-label">
                    카탈로그
                </h3>
                <ul class="menu-list"><li>
        <a class="is-flex" href="#PyTorch-XLA-설치하기">
        <span class="has-mr-6">1</span>
        <span>PyTorch/XLA 설치하기</span>
        </a></li><li>
        <a class="is-flex" href="#데이터셋-준비하기">
        <span class="has-mr-6">2</span>
        <span>데이터셋 준비하기</span>
        </a></li><li>
        <a class="is-flex" href="#중요-torch-xla-패키지로-Device-지정하기">
        <span class="has-mr-6">3</span>
        <span>[중요!] torch-xla 패키지로 Device 지정하기</span>
        </a></li><li>
        <a class="is-flex" href="#TPU로-PyTorch-딥러닝-모델-학습시키기">
        <span class="has-mr-6">4</span>
        <span>TPU로 PyTorch 딥러닝 모델 학습시키기</span>
        </a></li><li>
        <a class="is-flex" href="#TPU-코어-FULL-활용하기">
        <span class="has-mr-6">5</span>
        <span>TPU 코어 FULL 활용하기</span>
        </a></li><li>
        <a class="is-flex" href="#References">
        <span class="has-mr-6">6</span>
        <span>References</span>
        </a></li></ul>
            </div>
        </div>
    </div>

    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    Beomi&#39;s Tech Blog
                
                </a>
                <p class="is-size-7">
                &copy; 2021 Junbum Lee&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("ko");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://beomi.github.io',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>








<script src="/js/main.js" defer></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
</body>
</html>