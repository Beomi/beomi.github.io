<!DOCTYPE html>
<html  lang="ko">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.1" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>나만의 웹 크롤러 만들기 with Requests/BeautifulSoup - Beomi&#39;s Tech blog</title>








<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89162642-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-89162642-1');
</script>

    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    


<link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="is-1-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                Beomi&#39;s Tech Blog
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="https://junbuml.ee">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-12 has-order-2 column-main">
<div class="card">
    
    <div class="card-image">
        <span  class="image is-7by1">
            <img class="thumbnail" src="https://d1sr4ybm5bj1wl.cloudfront.net/img/2017-01-19-HowToMakeWebCrawler/crawler.jpg" alt="나만의 웹 크롤러 만들기 with Requests/BeautifulSoup">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-01-19T15:00:00.000Z">2017-01-20</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/python/">python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/python/howtomakewebcrawler/">howtomakewebcrawler</a>
                </div>
                
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                나만의 웹 크롤러 만들기 with Requests/BeautifulSoup
            
        </h1>
        <div class="content">
            <blockquote>
<p>좀 더 보기 편한 <a href="https://beomi.github.io/gb-crawling/">깃북 버전의 나만의 웹 크롤러 만들기</a>가 나왔습니다!</p>
</blockquote>
<blockquote>
<p>(@2017.03.18) 본 블로그 테마가 업데이트되면서 구 블로그의 URL은 <a href="https://beomi.github.io/beomi.github.io_old/로">https://beomi.github.io/beomi.github.io_old/로</a> 변경되었습니다. 예제 코드에서는 변경을 완료하였지만 캡쳐 화면은 변경하지 않았으니 유의 바랍니다.</p>
</blockquote>
<h1 id="웹-크롤러란"><a href="#웹-크롤러란" class="headerlink" title="웹 크롤러란?"></a>웹 크롤러란?</h1><p>우리가 어떤 정보를 브라우저에서만 보는 것 뿐 아니라 그 정보들을 내가 이용하기 편한 방식(ex: json)으로 로컬에 저장하고 싶을 때가 있다.</p>
<p><a href="https://www.httrack.com/">HTTrack</a>의 경우에는 웹을 그대로 자신의 컴퓨터로 복사를 해오지만, 내가 원하는 방식으로의 가공까지는 제공해주지 않는다.</p>
<p>Python을 이용하면 간단한 코드 몇줄 만으로도 쉽게 웹 사이트에서 원하는 정보만을 가져올 수 있다.</p>
<h1 id="웹에서-정보-가져오기"><a href="#웹에서-정보-가져오기" class="headerlink" title="웹에서 정보 가져오기"></a>웹에서 정보 가져오기</h1><h2 id="Requests"><a href="#Requests" class="headerlink" title="Requests"></a>Requests</h2><p>Python에는 <code>requests</code>라는 유명한 http request 라이브러리가 있다.</p>
<h3 id="설치하기"><a href="#설치하기" class="headerlink" title="설치하기"></a>설치하기</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>

<p>pip로 간단하게 설치가 가능하다.</p>
<h3 id="이용방법"><a href="#이용방법" class="headerlink" title="이용방법"></a>이용방법</h3><p>Python 파일 하나(ex: parser.py)를 만들어 <code>requests</code>를 import 해준다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parser.py</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># HTTP GET Request</span></span><br><span class="line">req = requests.get(<span class="string">'https://beomi.github.io/beomi.github.io_old/'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># HTML 소스 가져오기</span></span><br><span class="line">html = req.text</span><br><span class="line"><span class="comment"># HTTP Header 가져오기</span></span><br><span class="line">header = req.headers</span><br><span class="line"><span class="comment"># HTTP Status 가져오기 (200: 정상)</span></span><br><span class="line">status = req.status_code</span><br><span class="line"><span class="comment"># HTTP가 정상적으로 되었는지 (True/False)</span></span><br><span class="line">is_ok = req.ok</span><br></pre></td></tr></table></figure>

<p>위 코드에서 우리가 사용할 것은 HTML 소스를 이용하는 것이다. 따라서 <code>html=req.text</code>를 이용한다.</p>
<h2 id="BeautifulSoup"><a href="#BeautifulSoup" class="headerlink" title="BeautifulSoup"></a>BeautifulSoup</h2><p>Requests는 정말 좋은 라이브러리이지만, html을 ‘의미있는’, 즉 Python이 이해하는 객체 구조로 만들어주지는 못한다. 위에서 req.text는 python의 문자열(str)객체를 반환할 뿐이기 때문에 정보를 추출하기가 어렵다.</p>
<p>따라서 <code>BeautifulSoup</code>을 이용하게 된다. 이 BeautifulSoup은 html 코드를 Python이 이해하는 객체 구조로 변환하는 Parsing을 맡고 있고, 이 라이브러리를 이용해 우리는 제대로 된 ‘의미있는’ 정보를 추출해 낼 수 있다.</p>
<h3 id="설치하기-1"><a href="#설치하기-1" class="headerlink" title="설치하기"></a>설치하기</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install bs4</span><br></pre></td></tr></table></figure>

<p>BeautifulSoup을 직접 쳐서 설치하는 것도 가능하지만, bs4라는 wrapper라이브러리를 통해 설치하는 방법이 더 쉽고 안전하다.</p>
<h3 id="이용방법-1"><a href="#이용방법-1" class="headerlink" title="이용방법"></a>이용방법</h3><p>위에서 이용한 parser.py파일을 좀 더 다듬어 보자.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parser.py</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># HTTP GET Request</span></span><br><span class="line">req = requests.get(<span class="string">'https://beomi.github.io/beomi.github.io_old/'</span>)</span><br><span class="line"><span class="comment"># HTML 소스 가져오기</span></span><br><span class="line">html = req.text</span><br><span class="line"><span class="comment"># BeautifulSoup으로 html소스를 python객체로 변환하기</span></span><br><span class="line"><span class="comment"># 첫 인자는 html소스코드, 두 번째 인자는 어떤 parser를 이용할지 명시.</span></span><br><span class="line"><span class="comment"># 이 글에서는 Python 내장 html.parser를 이용했다.</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure>

<p>이제 <code>soup</code> 객체에서 원하는 정보를 찾아낼 수 있다.</p>
<p>BeautifulSoup에서는 여러가지 기능을 제공하는데, 여기서는 <code>select</code>를 이용한다. <code>select</code>는 CSS Selector를 이용해 조건과 일치하는 모든 객체들을 List로 반환해준다.</p>
<p>예시로 이 블로그의 모든 제목을 가져와 보도록 하자.</p>
<p align="center">
<img src="/img/2017-01-19-HowToMakeWebCrawler/blog_page.png"/>
</p>

<p>크롬에 내장된 검사도구(요소 위에서 우측 클릭 후 검사)를 이용해보면 현재 title은 a 태그로 구성되어있다는 것을 알 수 있다. 이 상황에서 모든 a 태그를 가져올 수도 있지만, 보다 정확하게 가져오기 위해 CSS Selector를 확인해 보자.</p>
<p align="center">
<img src="/img/2017-01-19-HowToMakeWebCrawler/blog_css_selector.png"/>
</p>

<p>확인해보니 아래와 같은 코드가 나왔다.</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h3</span><span class="selector-pseudo">:nth-child(4)</span> &gt; <span class="selector-tag">a</span></span><br></pre></td></tr></table></figure>

<p>하지만 <code>:nth-child(4)</code> 등이 붙어있는 것으로 보아 현재 요소를 ‘정확하게’ 특정하고 있기 때문에, 좀 더 유연하게 만들어 주기 위해 아래와 같이 selector를 바꿔준다.(위 코드는 단 하나의 링크만을 특정하고, 아래 코드는 css selector에 일치하는 모든 요소를 가리킨다.)</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">h3</span> &gt; <span class="selector-tag">a</span></span><br></pre></td></tr></table></figure>

<p>이제 parsing.py파일을 더 다듬어 보자.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parser.py</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">req = requests.get(<span class="string">'https://beomi.github.io/beomi.github.io_old/'</span>)</span><br><span class="line">html = req.text</span><br><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line"><span class="comment"># CSS Selector를 통해 html요소들을 찾아낸다.</span></span><br><span class="line">my_titles = soup.select(</span><br><span class="line">    <span class="string">'h3 &gt; a'</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>위 코드에서 my_titles는 string의 list가 아니라 soup객체들의 list이다. 따라서 태그의 속성들도 이용할 수 있는데, a 태그의 경우 href속성이 대표적인 예시다.</p>
<p>soup객체는 &lt;태그&gt;&lt;/태그&gt;로 구성된 요소를 Python이 이해하는 상태로 바꾼 것이라 볼 수 있다. 따라서 여러가지로 조작이 가능하다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parser.py</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">req = requests.get(<span class="string">'https://beomi.github.io/beomi.github.io_old/'</span>)</span><br><span class="line">html = req.text</span><br><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">my_titles = soup.select(</span><br><span class="line">    <span class="string">'h3 &gt; a'</span></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># my_titles는 list 객체</span></span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> my_titles:</span><br><span class="line">    <span class="comment"># Tag안의 텍스트</span></span><br><span class="line">    print(title.text)</span><br><span class="line">    <span class="comment"># Tag의 속성을 가져오기(ex: href속성)</span></span><br><span class="line">    print(title.get(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure>

<p>위와 같이 코드를 처리할 경우 a 태그 안의 텍스트와 a 태그의 href속성의 값을 가져오게 된다. 위 코드에서 title 객체는 python의 dictionary와 같이 태그의 속성들을 저장한다. 따라서 <code>title.get(&#39;속성이름&#39;)</code>나 <code>title[&#39;속성이름&#39;]</code>처럼 이용할 수 있다.</p>
<p><code>select</code>를 통해 요소들을 가져온 이후에는 각자가 생각하는 방식으로 python코드를 이용해 저장하면 된다.</p>
<h2 id="정리-예제"><a href="#정리-예제" class="headerlink" title="정리 예제"></a>정리 예제</h2><p>아래 코드는 크롤링한 데이터를 Python파일와 같은 위치에 <code>result.json</code>을 만들어 저장하는 예제다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parser.py</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># python파일의 위치</span></span><br><span class="line">BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line"></span><br><span class="line">req = requests.get(<span class="string">'https://beomi.github.io/beomi.github.io_old/'</span>)</span><br><span class="line">html = req.text</span><br><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">my_titles = soup.select(</span><br><span class="line">    <span class="string">'h3 &gt; a'</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">data = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> my_titles:</span><br><span class="line">    data[title.text] = title.get(<span class="string">'href'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(os.path.join(BASE_DIR, <span class="string">'result.json'</span>), <span class="string">'w+'</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json.dump(data, json_file)</span><br></pre></td></tr></table></figure>

<h1 id="다음-가이드"><a href="#다음-가이드" class="headerlink" title="다음 가이드"></a>다음 가이드</h1><p>다음 가이드에서는 <code>Session</code>을 이용해 어떻게 웹 사이트에 로그인을 하고, 로그인 상태를 유지하며 브라우징을 하는지에 대해 알아보겠습니다.</p>
<p>다음 가이드: <a href="/2017/01/20/HowToMakeWebCrawler-With-Login/">나만의 웹 크롤러 만들기(2): Login With Session</a></p>

        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2017/01/20/HowToMakeWebCrawler-With-Login/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">나만의 웹 크롤러 만들기(2): Login with Session</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2016/12/28/HowToSetup-Virtualenv-VirtualenvWrapper/">
                <span class="level-item">Virtualenv/VirtualenvWrapper OS별 설치&amp;이용법</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    Beomi&#39;s Tech Blog
                
                </a>
                <p class="is-size-7">
                &copy; 2021 Junbum Lee&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("ko");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://beomi.github.io',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Kembali ke atas" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>








<script src="/js/main.js" defer></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
</body>
</html>