<!DOCTYPE html>
<html  lang="ko">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.1" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>PySpark &amp; Hadoop: 2) EMR 클러스터 띄우고 PySpark로 작업 던지기 - Beomi&#39;s Tech blog</title>








<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89162642-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-89162642-1');
</script>

    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    


<link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="is-1-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                Beomi&#39;s Tech Blog
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="https://junbuml.ee">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-12 has-order-2 column-main">
<div class="card">
    
    <div class="card-image">
        <span  class="image is-7by1">
            <img class="thumbnail" src="https://d1sr4ybm5bj1wl.cloudfront.net/img/PySpak_n_Hadoop_EMR_and_PySpark.png" alt="PySpark &amp; Hadoop: 2) EMR 클러스터 띄우고 PySpark로 작업 던지기">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-11-26T15:00:00.000Z">2017-11-27</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/python/">python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/python/pyspark/">pyspark</a>
                </div>
                
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                PySpark &amp; Hadoop: 2) EMR 클러스터 띄우고 PySpark로 작업 던지기
            
        </h1>
        <div class="content">
            <blockquote>
<p>이번 글은 <a href="/2017/11/09/Install-PySpark-and-Hadoop-on-Ubuntu-16-04">PySpark &amp; Hadoop: 1) Ubuntu 16.04에 설치하기</a>와 이어지는 글입니다.</p>
</blockquote>
<h2 id="들어가며"><a href="#들어가며" class="headerlink" title="들어가며"></a>들어가며</h2><p>이전 글에서 우분투에 JAVA/Hadoop/PySpark를 설치해 spark를 통해 EMR로 작업을 던질 EC2를 하나 생성해보았습니다. 이번에는 동일한 VPC그룹에 EMR 클러스터를 생성하고 PySpark의 <code>yarn</code>설정을 통해 원격 EMR에 작업을 던져봅시다.</p>
<h2 id="EMR-클러스터-띄우기"><a href="#EMR-클러스터-띄우기" class="headerlink" title="EMR 클러스터 띄우기"></a>EMR 클러스터 띄우기</h2><p>AWS 콘솔에 들어가 EMR을 검색해 EMR 대시보드로 들어갑시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2016.52.49.png" alt="AWS 콘솔에서 EMR검색하기"></p>
<p>EMR 대시보드에서 ‘클러스터 생성’을 클릭해주세요.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2016.53.53.png" alt="EMR 대시보드 첫화면에서 클러스터 생성 클릭"></p>
<p>이제 아래와 같이 클러스터이름을 적어주고, 시작 모드를 ‘클러스터’로, 릴리즈는 최신 릴리즈 버전(현 5.10이 최신)으로, 애플리케이션은 Spark를 선택해주세요.</p>
<p>그리고 EC2 키 페어를 갖고있다면 기존에 갖고있는 <code>.pem</code>파일을, 없다면 새 키를 만들고 진행하세요.</p>
<p>주황색 표시 한 부분 외에는 기본 설정값 그대로 두면 됩니다. 로깅은 필요한 경우 켜고 필요하지 않은 경우 꺼두면 됩니다.</p>
<p>그리고 할 작업에 따라 인스턴스 유형을 r(많은 메모리), c(많은 CPU), i(많은 스토리지), p(GPU)중 선택하고 인스턴스 개수를 원하는 만큼 선택해주면 됩니다.</p>
<p>많으면 많을수록 Spark작업이 빨리 끝나는 한편 비용도 그만큼 많이 듭니다. 여기서는 기본값인 <code>r3.xlarge</code> 인스턴스 3개로 진행해 봅시다. 인스턴스 3대가 생성되면 한대는 Master 노드가, 나머지 두대는 Core 노드가 됩니다. 앞으로 작업을 던지고 관리하는 부분은 모두 Master노드에서 이루어집니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2016.55.59.png" alt="EMR Spark 클러스터 만들기"></p>
<p>설정이 끝나고 나면 아래 ‘클러스터 생성’ 버튼을 눌러주세요.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.06.32.png" alt="클러스터 생성 클릭"></p>
<p>클러스터가 시작되고 ‘준비’ 단계가 될 때까지는 약간의 시간(1~3분)이 걸립니다. ‘마스터 퍼블릭 DNS’가 화면에 뜰 때까지 잠시 기다려 줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.11.49.png" alt="클러스터: PySpark화면"></p>
<p>클러스터가 준비가 완료되면 아래와 같이 ‘마스터 퍼블릭 DNS’ 주소가 나옵니다. </p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.19.56.png" alt="클러스터: PySpark DNS나온 화면"></p>
<p>‘마스터 퍼블릭 DNS’는 앞으로 설정할때 자주 사용하기 때문에 미리 복사를 해 둡시다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이번에 만들어진 클러스터의 마스터 퍼블릭 DNS</span></span><br><span class="line">ec2-13-124-83-135.ap-northeast-2.compute.amazonaws.com</span><br></pre></td></tr></table></figure>

<p>이렇게 나오면 우선 클러스터를 사용할 준비가 완료된 것으로 볼 수 있습니다. 이제 다시 앞 글에서 만든 EC2를 설정해봅시다.</p>
<h2 id="EC2-설정-관리하기"><a href="#EC2-설정-관리하기" class="headerlink" title="EC2 설정 관리하기"></a>EC2 설정 관리하기</h2><p>이제 EMR 클러스터가 준비가 완료되었으니 EC2 인스턴스에 다시 ssh로 접속을 해 봅시다.</p>
<p>이전 편인 <a href="/2017/11/09/Install-PySpark-and-Hadoop-on-Ubuntu-16-04">PySpark &amp; Hadoop: 1) Ubuntu 16.04에 설치하기</a>글을 읽고 따라 왔다면 여러분의 EC2에는 아마 JAVA와 PySpark, 그리고 Hadoop이 설치가 되어있을겁니다.</p>
<p>우리는 Hadoop의 <code>yarn</code>을 통해서 EMR 클러스터에 spark작업을 던져주기 때문에 이 부분을 설정을 조금 해줘야 합니다.</p>
<p>이전 편을 따라왔다면 아래 두 파일을 수정해주면 되고, 만약 따로 Hadoop을 설치해줬다면 <code>which hadoop</code>을 통해서 나오는 주소를 약간 수정해 사용해주면 됩니다.</p>
<p>우선 앞서 우리가 Hadoop을 설치해준 곳은 <code>/usr/local/hadoop/bin/hadoop</code> 입니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.32.44.png" alt="which hadoop"></p>
<p>그리고 우리가 수정해줘야 하는 두 파일은 위와 같은 위치에 있는 <code>core-site.xml</code>파일, 그리고 <code>yarn-site.xml</code> 파일입니다. 즉, 절대 경로는 아래와 같습니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># core-site.xml</span></span><br><span class="line">/usr/<span class="built_in">local</span>/hadoop/etc/hadoop/core-site.xml</span><br><span class="line"><span class="comment"># yarn-site.xml</span></span><br><span class="line">/usr/<span class="built_in">local</span>/hadoop/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>

<blockquote>
<p>만약 다른 곳에 설치했다면 <code>/하둡을설치한위치/etc/hadoop/</code> 안의 <code>core-site.xml</code>와 <code>yarn-site.xml</code>을 수정하면 됩니다.</p>
</blockquote>
<h3 id="core-site-xml-수정하기"><a href="#core-site-xml-수정하기" class="headerlink" title="core-site.xml 수정하기"></a><code>core-site.xml</code> 수정하기</h3><p>이제 <code>core-site.xml</code>파일을 수정해 봅시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.41.59.png" alt="core-site.xml 수정"></p>
<p><code>core-site.xml</code>에는 다음과 같이 <code>fs.defaultFS</code>라는 name을 가진 property를 하나 추가해주면 됩니다. 그리고 그 값을 <code>hdfs://마스터퍼블릭DNS</code>로 넣어줘야 합니다.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- core-site.xml --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ec2-13-124-83-135.ap-northeast-2.compute.amazonaws.com<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>수정은 <code>vim</code>이나 <code>nano</code>등의 편집기를 이용해주세요.</p>
<h3 id="yarn-site-xml-수정하기"><a href="#yarn-site-xml-수정하기" class="headerlink" title="yarn-site.xml 수정하기"></a><code>yarn-site.xml</code> 수정하기</h3><p>이제 다음 파일인 <code>yarn-site.xml</code>파일을 수정해 봅시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.46.19.png" alt="yarn-site.xml 수정"></p>
<p><code>yarn-site.xml</code>에는 다음과 같이 두가지 설정을 마스터퍼블릭DNS로 넣어줘야 합니다. <code>address</code>에는 포트도 추가적으로 붙여줘야 합니다.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ec2-13-124-83-135.ap-northeast-2.compute.amazonaws.com:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ec2-13-124-83-135.ap-northeast-2.compute.amazonaws.com<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>이렇게 두 파일을 수정해주었으면 EC2에서 설정을 수정할 부분은 끝났습니다.</p>
<h2 id="EMR-클러스터-설정-관리하기"><a href="#EMR-클러스터-설정-관리하기" class="headerlink" title="EMR 클러스터 설정 관리하기"></a>EMR 클러스터 설정 관리하기</h2><h3 id="같은버전-Python-설치하기"><a href="#같은버전-Python-설치하기" class="headerlink" title="같은버전 Python 설치하기"></a>같은버전 Python 설치하기</h3><p>Spark에서 파이썬 함수(혹은 파일)을 실행할 때 Spark가 실행되고있는 파이썬 버전과 PySpark등을 통해 Spark 서버로 요청된 파이썬 함수의 버전과 일치하지 않으면 Exception을 일으킵니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2020.53.05.png" alt="Python driver 3.4_3.5 Exception"></p>
<p>현재 EMR에 설치되어있는 python3은 3.4버전인데, EC2(Ubuntu 16.04)의 파이썬 버전은 3.5버전이기 때문에 Exception이 발생합니다. </p>
<p>아래 세 가지 방법 중 하나를 선택해 해결해주세요.</p>
<h4 id="첫번째-방법-Ubuntu-EC2에-Python3-4를-설치하기"><a href="#첫번째-방법-Ubuntu-EC2에-Python3-4를-설치하기" class="headerlink" title="첫번째 방법: Ubuntu EC2에 Python3.4를 설치하기"></a>첫번째 방법: Ubuntu EC2에 Python3.4를 설치하기</h4><p>Ubuntu16은 공식적으로 Python3.4를 지원하지 않습니다. 하지만 간단한 방법으로 Python3.4를 설치할 수 있습니다.</p>
<p>아래 세 줄을 입력해주세요.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:fkrull/deadsnakes</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install python3.4 -y</span><br></pre></td></tr></table></figure>

<p>이렇게 하면 Python3.4를 사용할 수 있습니다.</p>
<p>막 설치해준 Python3.4에는 아직 <code>pyspark</code>가 설치되어있지 않으니 아래 명령어로 <code>pyspark</code>를 설치해 줍시다.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3.4 -m pip install -U pyspark --no-cache</span><br></pre></td></tr></table></figure>

<p>이제 EMR 클러스터에 작업을 던져줍시다.</p>
<h4 id="두번째-방법-EMR을-이루는-인스턴스에-원하는-Python버전-3-5-를-설치하기"><a href="#두번째-방법-EMR을-이루는-인스턴스에-원하는-Python버전-3-5-를-설치하기" class="headerlink" title="두번째 방법: EMR을 이루는 인스턴스에 원하는 Python버전(3.5)를 설치하기"></a>두번째 방법: EMR을 이루는 인스턴스에 원하는 Python버전(3.5)를 설치하기</h4><p>EMR에 python3.5를 설치해 문제를 해결해 봅시다.</p>
<blockquote>
<p>만약 여러분이 Ubuntu 17버전을 사용한다면 기본적으로 Python3.6이 설치되어있기 때문에 아래 코드에서 <code>35</code> 대신 <code>36</code>을 이용해주시면 됩니다.</p>
</blockquote>
<p>이제 SSH를 통해 EMR Master에 접속해 봅시다.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod 400 sshkey.pem # ssh-add는 권한을 따집니다. 400으로 읽기권한만 남겨두세요.</span><br><span class="line">ssh-add sshkey.pem # 여러분의 .pem 파일 경로를 넣어주세요.</span><br><span class="line">ssh hadoop@ec2-13-124-83-135.ap-northeast-2.compute.amazonaws.com</span><br></pre></td></tr></table></figure>

<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2020.35.28.png" alt="SSH Login EMR"></p>
<p>로그인을 하고 나서 파이썬 버전을 알아봅시다. 파이썬 버전은 아래 사진처럼 볼 수 있습니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.24.59.png" alt="EMR python은 3.4버전"></p>
<p>파이썬이 3.4버전인것을 확인할 수 있습니다.</p>
<p>한편, EC2의 파이썬은 아래와 같이 3.5버전입니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2017.25.24.png" alt="EC2 python은 3.5버전"></p>
<p>이제 EMR에 Python3.5를 설치해 줍시다.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install python35</span><br></pre></td></tr></table></figure>

<p>위 명령어를 입력하면 python3.5버전이 설치됩니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2020.41.22.png" alt="yum install python35"></p>
<p>Y/N을 물어보면 y를 눌러줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2020.42.03.png" alt="Press y to install"></p>
<p><code>python3 -V</code>를 입력해보면 성공적으로 파이썬 3.5버전이 설치된 것을 볼 수 있습니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2020.44.05.png" alt="Python3.5.1"></p>
<blockquote>
<p>이 과정을 Master / Core 각 인스턴스별로 진행해주시면 됩니다. SSH로 접속 후 <code>python35</code>만 설치하면 됩니다.</p>
</blockquote>
<p>이제 EMR 클러스터에 작업을 던져줍시다.</p>
<h4 id="세번째-방법-EMR-클러스터-부트스트랩-이용하기"><a href="#세번째-방법-EMR-클러스터-부트스트랩-이용하기" class="headerlink" title="세번째 방법: EMR 클러스터 부트스트랩 이용하기"></a>세번째 방법: EMR 클러스터 부트스트랩 이용하기</h4><p>두번째 방법과 같이 EMR 클러스터를 이루는 인스턴스 하나하나에 들어가 설치를 진행하는 것은 굉장히 비효율적입니다.</p>
<p>그래서 EMR 클러스터가 생성되기 전에 두번째 방법에서와 같이 EMR 클러스터 내에 Python35, Python36을 모두 설치해두면 앞으로도 문제가 없을거에요.</p>
<p>이때 사용할 수 있는 방법이 ‘bootstrap action’ 입니다. bootstrap action은 EMR 클러스터가 생성되기 전 <code>.sh</code>같은 쉘 파일등을 실행할 수 있습니다.</p>
<p>우선 우리가 실행해줄 <code>installpy3536.sh</code> 파일을 로컬에서 하나 만들어 줍시다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">sudo yum install python34 -y</span><br><span class="line">sudo yum install python35 -y</span><br><span class="line">sudo yum install python36 -y</span><br></pre></td></tr></table></figure>

<p>EMR 클러스터는 아마존리눅스상에서 돌아가기 때문에 <code>yum</code>을 통해 패키지를 설치할 수 있습니다. 각각 python3.4/3.5/3.6버전을 받아 설치해주는 명령어입니다.</p>
<p>이 파일을 s3에 올려줍시다.</p>
<p>우선 빈 버킷 혹은 기존 버킷에 파일을 올려주세요.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.13.13.png" alt="빈 s3 버킷 만들기"></p>
<p>파일 권한은 기본 권한 그대로 두면 됩니다. 그리고 이 파일은 AWS 외부에서 접근하지 않기 때문에 퍼블릭으로 해둘 필요는 없습니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.13.46.png" alt="파일 업로드 완료"></p>
<p>이제 EMR을 실행하러 가 봅시다.</p>
<p>앞서서는 ‘빠른 옵션’을 이용했지만 이제 ‘고급 옵션’을 이용해야 합니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.15.11.png" alt="새 EMR 클러스터 만들기"></p>
<p>고급 옵션에서 소프트웨어 구성을 다음과 같이 체크하고 ‘다음’을 눌러줍시다. </p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.17.53.png" alt="단계1: 소프트웨어 및 단계"></p>
<p>다음 단계인 ‘하드웨어’는 기본값 혹은 필요한 만큼 설정해준 뒤 ‘다음’을 눌러줍시다. 여기서는 기본값으로 넣어줬습니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.20.01.png" alt="단계2: 하드웨어"></p>
<p>이번 단계인 ‘일반 클러스터 설정’이 중요합니다. 여기에서 ‘부트스트랩 작업’을 누르고 ‘사용자 지정 작업’을 선택해주세요.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.21.20.png" alt="단계3: 일반 클러스터 설정"></p>
<p>‘사용자 지정 작업’을 선택한 뒤 ‘구성 및 추가’를 눌러주세요.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.22.06.png" alt="구성 및 추가"></p>
<p>추가를 누르면 다음과 같이 ‘이름’, ‘스크립트 위치’를 찾아줘야 합니다. 이름을 <code>InstallPython343536</code>이라고 지어봅시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.23.32.png" alt=""></p>
<p>이제 스크립트 옆 폴더 버튼을 눌러줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.25.01.png" alt=""></p>
<p>아까 만든 <code>installpy3536.sh</code>파일이 있는 버킷에 찾아들어가 <code>installpy3536.sh</code> 파일을 선택해줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.25.18.png" alt=""></p>
<p>선택을 눌러준 뒤 ‘추가’를 눌러줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.26.51.png" alt=""></p>
<p>아래와 같이 ‘부트스트랩 작업’에 추가되었다면 ‘다음’을 눌러 클러스터를 만들어 줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.28.00.png" alt=""></p>
<p>이제 마지막으로 SSH접속을 위한 키 페어를 선택한 후 ‘클러스터 생성’을 눌러줍시다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2013.29.15.png" alt=""></p>
<p>이제 생성된 EMR 클러스터에는 python3.4/3.5/3.6이 모두 설치되어있습니다. 이 버전 선택은 아래 <code>PYSPARK_PYTHON</code> 값을 설정할때 변경해 사용하면 됩니다.</p>
<h3 id="ubuntu-유저-만들고-hadoop그룹에-추가하기"><a href="#ubuntu-유저-만들고-hadoop그룹에-추가하기" class="headerlink" title="ubuntu 유저 만들고 hadoop그룹에 추가하기"></a><code>ubuntu</code> 유저 만들고 <code>hadoop</code>그룹에 추가하기</h3><p>python 설치를 마쳤다면 이제 <code>ubuntu</code>유저를 만들어줘야 합니다.</p>
<p>EMR 클러스터 마스터 노드에 작업을 추가해 줄 경우 기본적으로 작업을 실행한 유저(우분투 EC2에서 요청시 기본 유저는 <code>ubuntu</code>)의 이름으로 마스터 노드에서 요청한 유저의 홈 폴더를 찾습니다.</p>
<p>만약 EC2에서 EMR로 요청한다면 <code>ubuntu</code>라는 계정 이름으로 EMR 마스터 노드에서 <code>/home/ubuntu</code>라는 폴더를 찾아 이 폴더에 작업할 파이썬 파일과 의존 패키지 등을 두고 작업을 진행합니다. 하지만 EMR은 기본적으로 <code>hadoop</code>이라는 계정을 사용하고, 따라서 <code>ubuntu</code>라는 유저는 추가해줘야 합니다. 그리고 우리가 새로 만들어준 <code>ubuntu</code> 유저는 하둡에 접근할 권한이 없기 때문에 이 유저를 <code>hadoop</code>그룹에 추가해줘야 합니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-27%2019.52.07.png" alt="우분투 계정 만들고 하둡 그룹에 추가"></p>
<p>위 사진처럼 두 명령어를 입력해 줍시다.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser ubuntu</span><br><span class="line">sudo usermod -a -G hadoop ubuntu</span><br></pre></td></tr></table></figure>

<p>첫 명령어는 <code>ubuntu</code>라는 유저를 만들고 다음에서 <code>hadoop</code>이라는 그룹에 <code>ubuntu</code>유저를 추가합니다.</p>
<p>이제 우리는 EC2에서 EMR로 분산처리할 함수들을 보낼 수 있습니다.</p>
<h2 id="마무리-파이-pi-계산-예제-실행하기"><a href="#마무리-파이-pi-계산-예제-실행하기" class="headerlink" title="마무리: 파이(pi) 계산 예제 실행하기"></a>마무리: 파이(pi) 계산 예제 실행하기</h2><p>한번 PySpark의 기본 예제중 하나인 <code>pi</code>(원주율) 계산을 진행해 봅시다.</p>
<p>공식 예제: <a href="https://github.com/apache/spark/blob/master/examples/src/main/python/pi.py">https://github.com/apache/spark/blob/master/examples/src/main/python/pi.py</a></p>
<p>공식 예제는 스파크와 하둡을 로컬에서 사용합니다. 하지만 우리는 EMR 클러스터에 작업을 던져줄 것이기 때문에 약간 코드를 변경해줘야 합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pi.py</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">"PYSPARK_PYTHON"</span>] = <span class="string">"/usr/bin/python34"</span> <span class="comment"># python3.5라면 /usr/bin/python35</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        Usage: pi [partitions]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 이 부분을 추가해주시고</span></span><br><span class="line">    spark = SparkSession \</span><br><span class="line">        .builder \</span><br><span class="line">        .master(<span class="string">"yarn"</span>) \</span><br><span class="line">        .appName(<span class="string">"PySpark"</span>) \</span><br><span class="line">        .getOrCreate()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 이부분을 주석처리해주세요.</span></span><br><span class="line">    <span class="comment">#spark = SparkSession\</span></span><br><span class="line">    <span class="comment">#    .builder\</span></span><br><span class="line">    <span class="comment">#    .appName("PythonPi")\</span></span><br><span class="line">    <span class="comment">#    .getOrCreate()</span></span><br><span class="line">    </span><br><span class="line">    partitions = int(sys.argv[<span class="number">1</span>]) <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">    n = <span class="number">100000</span> * partitions</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(_)</span>:</span></span><br><span class="line">        x = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        y = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x ** <span class="number">2</span> + y ** <span class="number">2</span> &lt;= <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    count = spark.sparkContext.parallelize(range(<span class="number">1</span>, n + <span class="number">1</span>), partitions).map(f).reduce(add)</span><br><span class="line">    print(<span class="string">"Pi is roughly %f"</span> % (<span class="number">4.0</span> * count / n))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure>

<p>기존 코드는 <code>builder</code>를 통해 로컬에서 작업을 던져주지만 이렇게 <code>.master(&quot;yarn&quot;)</code>을 추가해주면 yarn 설정을 통해 아래 작업이 EMR 클러스터에서 동작하게 됩니다.</p>
<p>EC2상에서 아래 명령어로 위 파이썬 파일을 실행해 봅시다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3.4 pi.py</span><br></pre></td></tr></table></figure>

<p>실행을 해 보면 결과가 잘 나오는 것을 볼 수 있습니다.</p>
<p><img src="https://d1sr4ybm5bj1wl.cloudfront.net/img/dropbox/Screenshot%202017-11-28%2010.29.40.png" alt="pi is roughly 3.144720"></p>
<blockquote>
<p>만약 두번째/세번째 방법으로 Python3.5를 설치해주셨다면 별다른 설정 없이 <code>python3 pi.py</code>로 실행하셔도 됩니다.</p>
</blockquote>
<h3 id="자주-보이는-에러-경고"><a href="#자주-보이는-에러-경고" class="headerlink" title="자주 보이는 에러/경고"></a>자주 보이는 에러/경고</h3><h4 id="WARN-yarn-Client-Same-path-resource"><a href="#WARN-yarn-Client-Same-path-resource" class="headerlink" title="WARN yarn.Client: Same path resource"></a>WARN yarn.Client: Same path resource</h4><p>새 task를 Spark로 넘겨줄 때 마다 패키지를 찾기 때문에 나오는 에러입니다. 무시해도 됩니다.</p>
<h4 id="Initial-job-has-not-accepted-any-resources"><a href="#Initial-job-has-not-accepted-any-resources" class="headerlink" title="Initial job has not accepted any resources"></a>Initial job has not accepted any resources</h4><p>EMR 설정 중 <code>spark.dynamicAllocation.enabled</code>가 <code>True</code>일 경우 생기는 문제입니다.</p>
<p>위 <code>pi.py</code>파일 코드를 일부 수정해주세요.</p>
<p>기존에 있던 <code>spark</code> 생성하는 부분에 아래 <code>config</code> 몇줄을 추가해주세요.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기존 코드를 지우고</span></span><br><span class="line"><span class="comment"># spark = SparkSession \</span></span><br><span class="line"><span class="comment">#     .builder \</span></span><br><span class="line"><span class="comment">#     .master("yarn") \</span></span><br><span class="line"><span class="comment">#     .appName("PySpark") \</span></span><br><span class="line"><span class="comment">#     .getOrCreate()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 아래 코드로 바꿔주세요.</span></span><br><span class="line">spark = SparkSession.builder \</span><br><span class="line">    .master(<span class="string">"yarn"</span>) \</span><br><span class="line">    .appName(<span class="string">"PySpark"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.executor.memory"</span>, <span class="string">"512M"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.yarn.am.memory"</span>, <span class="string">"512M"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.executor.cores"</span>, <span class="number">2</span>) \</span><br><span class="line">    .config(<span class="string">"spark.executor.instances"</span>, <span class="number">1</span>) \</span><br><span class="line">    .config(<span class="string">"spark.dynamicAllocation.enabled"</span>, <span class="literal">False</span>) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<p>이때 각 config별로 설정되는 값은 여러분이 띄운 EMR에 따라 설정해줘야 합니다. 만약 여러분이 <code>r3.xlarge</code>를 선택했다면 8개의 vCPU, 30.5 GiB 메모리를 사용하기 때문에 저 설정 숫자들을 높게 잡아도 되지만, 만약 <code>c4.large</code>를 선택했다면 2개의 vCPU, 3.8 GiB 메모리를 사용하기 때문에 코드에서 설정한 CPU코어수 혹은 메모리 용량이 클러스터의 CPU개수와 메모리 용량을 초과할 경우 에러가 납니다.</p>

        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2017/11/28/Flask-CSV-Response/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">한글이 보이는 Flask CSV Response 만들기</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2017/11/20/Deploy-Gitbook-to-Github-Pages/">
                <span class="level-item">깃헙 Pages에 깃북 배포하기</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    Beomi&#39;s Tech Blog
                
                </a>
                <p class="is-size-7">
                &copy; 2021 Junbum Lee&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("ko");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://beomi.github.io',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>








<script src="/js/main.js" defer></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
</body>
</html>