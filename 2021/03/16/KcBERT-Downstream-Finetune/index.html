<!DOCTYPE html>
<html  lang="ko">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.1" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>KcBERT Finetune with PyTorch-Lightning v1.3.0 - Beomi&#39;s Tech blog</title>








<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89162642-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-89162642-1');
</script>

    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    


<link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="is-2-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                Beomi&#39;s Tech Blog
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="https://junbuml.ee">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="ì¹´íƒˆë¡œê·¸" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main">
<div class="card">
    
    <div class="card-image">
        <span  class="image is-7by1">
            <img class="thumbnail" src="https://cdn.jsdelivr.net/gh/beomi/blog-img@master/2021/03/16/1*VZpuai6qP4iNLc7opAkQxA.jpeg" alt="KcBERT Finetune with PyTorch-Lightning v1.3.0">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2021-03-15T15:00:00.000Z">2021-03-16</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/nlp/">nlp</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/nlp/languagemodel/">languagemodel</a>
                </div>
                
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                KcBERT Finetune with PyTorch-Lightning v1.3.0
            
        </h1>
        <div class="content">
            <h2 id="ë“¤ì–´ê°€ë©°"><a href="#ë“¤ì–´ê°€ë©°" class="headerlink" title="ë“¤ì–´ê°€ë©°"></a>ë“¤ì–´ê°€ë©°</h2><p>KcBERTë¥¼ ê³µê°œí•˜ë©° NSMCë¥¼ ì˜ˆì œë¡œ PyTorch-Lightningì„ ì´ìš©í•œ Downstream task Fine-tuneì„ ì§„í–‰í•˜ëŠ” Colab ì˜ˆì œ(<a href="https://colab.research.google.com/drive/1dFC0FL-521m7CL_PSd8RLKq67jgTJVhL?usp=sharing">ë§í¬</a>)ë¥¼ ë§Œë“¤ì–´ ë°°í¬í•´ë³´ì•˜ë‹¤.</p>
<p>í•œí¸, Transformersì˜ ë²„ì „ê³¼ PyTorch-Lightning, ê·¸ë¦¬ê³  PyTorchì˜ ë²„ì „ ìì²´ê°€ ì˜¬ë¼ê°€ë©´ì„œ ì—¬ëŸ¬ê°€ì§€ì˜ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ê³ , ì—¬ëŸ¬ í•¨ìˆ˜ë‚˜ ë‚´ì¥ ì„¸íŒ… ë“±ì´ ê½¤ë‚˜ ë§ì´ Deprecatedë˜ì—ˆë‹¤.</p>
<p>ì‚¬ëŒì€ ì–¸ì œë‚˜ ê·€ì°®ìŒì— ì§€ë°°ë˜ê¸° ë•Œë¬¸ì— ì½”ë“œë¥¼ í•œë²ˆ ë§Œë“¤ê³  ìµœì†Œí•œì˜ ìˆ˜ì •ë§Œì„ í•˜ë©´ì„œ â€˜ëŒì•„ê°€ê¸°ëŠ” í•˜ëŠ”â€™ ìˆ˜ì¤€ìœ¼ë¡œ ì½”ë“œë¥¼ ìœ ì§€í–ˆë‹¤.</p>
<p>í•˜ì§€ë§Œ ì‹¤í–‰ì‹œë§ˆë‹¤ ëœ¨ëŠ” â€˜Deprecate warningsâ€™ì— ì§ˆë¦¬ëŠ” ìˆœê°„ì´ ì˜¤ê³ , ì§€ê¸ˆì´ ë°”ë¡œ ê·¸ ìˆœê°„ì´ë¼ ê¸°ì¡´ ì½”ë“œë¥¼ â€œë³´ë‹¤ ì¢‹ê²Œâ€, ê·¸ë¦¬ê³  ê¸°ì™• ìˆ˜ì •í•˜ëŠ” ê¹€ì— <strong>ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥(ì„±ëŠ¥ì— ë”°ë¥¸) / Logging ì„œë¹„ìŠ¤ ì—°ë™ / Inference ì½”ë“œ ì¶”ê°€</strong>ë¥¼ ì§„í–‰í•´ë³´ë©´ ì–´ë–¨ê¹Œ ì‹¶ë‹¤.</p>
<blockquote>
<p>ì´ ê¸€ì€ <a href="https://colab.research.google.com/drive/1IPkZo1Wd-DghIOK6gJpcb0Dv4_Gv2kXB?usp=sharing">ì´ Colab ë…¸íŠ¸ë¶(ë§í¬)</a> ì—ì„œ ì§ì ‘ ì‹¤í–‰í•´ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</blockquote>
<a id="more"></a>

<h2 id="Args-Hparams"><a href="#Args-Hparams" class="headerlink" title="Args? Hparams?"></a>Args? Hparams?</h2><h3 id="AS-IS"><a href="#AS-IS" class="headerlink" title="AS-IS"></a>AS-IS</h3><p>ìš°ì„  ê°€ì¥ ì´ìŠˆì˜€ë˜ ë¶€ë¶„ì´ì ëª¨ë¸ ì €ì¥ì´ ë˜ì§€ ì•ŠëŠ” ë§Œì•…ì˜ ê·¼ì›ì€ ë°”ë¡œ <code>class Args</code> ì˜€ë‹¤.</p>
<p>ì›ë˜ëŠ” <code>Tap</code> ì´ë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ CLIì—ì„œ argsë¥¼ ì‰½ê²Œ ì˜¤ë²„ë¼ì´ë”© í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” ê²ƒì´ ëª©ì ì´ì—ˆì§€ë§Œâ€¦ ì˜ˆì œ ì½”ë“œë¥¼ Google Colabì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ì œì‘ì„ ë³€ê²½í•˜ë‹¤ë³´ë‹ˆ, ë‹¨ìˆœí•œ dataset classë¡œ ëŒ€ì²´í•´ ì„¤ì •ì„ ë‹¨ìˆœí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰í–ˆë‹¤.</p>
<p>ì•„ë˜ì™€ ê°™ì´ ê°’ì„ ë„£ì„ ìˆ˜ ìˆë„ë¡ ë˜ì–´ìˆê³ , ê° ê°’ì€ <code>args.random_seed</code> ì™€ ê°™ì´ ì•¡ì„¸ìŠ¤ í•˜ê±°ë‚˜ ì˜¤ë²„ë¼ì´ë”© í•  ìˆ˜ ìˆë„ë¡ ì„¸íŒ…ì„ í•´ ë‘ì—ˆë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Arg</span>:</span></span><br><span class="line">    random_seed: int = <span class="number">42</span>  <span class="comment"># Random Seed</span></span><br><span class="line">    pretrained_model: str = <span class="string">'beomi/kcbert-large'</span>  <span class="comment"># Transformers PLM name</span></span><br><span class="line">    pretrained_tokenizer: str = <span class="string">''</span>  <span class="comment"># Optional, Transformers Tokenizer Name. Overrides `pretrained_model`</span></span><br><span class="line">    auto_batch_size: str = <span class="string">'power'</span>  <span class="comment"># Let PyTorch Lightening find the best batch size </span></span><br><span class="line">    batch_size: int = <span class="number">0</span>  <span class="comment"># Optional, Train/Eval Batch Size. Overrides `auto_batch_size` </span></span><br><span class="line">    lr: float = <span class="number">5e-6</span>  <span class="comment"># Starting Learning Rate</span></span><br><span class="line">    epochs: int = <span class="number">20</span>  <span class="comment"># Max Epochs</span></span><br><span class="line">    max_length: int = <span class="number">150</span>  <span class="comment"># Max Length input size</span></span><br><span class="line">    report_cycle: int = <span class="number">100</span>  <span class="comment"># Report (Train Metrics) Cycle</span></span><br><span class="line">    train_data_path: str = <span class="string">"nsmc/ratings_train.txt"</span>  <span class="comment"># Train Dataset file </span></span><br><span class="line">    val_data_path: str = <span class="string">"nsmc/ratings_test.txt"</span>  <span class="comment"># Validation Dataset file </span></span><br><span class="line">    cpu_workers: int = os.cpu_count()  <span class="comment"># Multi cpu workers</span></span><br><span class="line">    test_mode: bool = <span class="literal">False</span>  <span class="comment"># Test Mode enables `fast_dev_run`</span></span><br><span class="line">    optimizer: str = <span class="string">'AdamW'</span>  <span class="comment"># AdamW vs AdamP</span></span><br><span class="line">    lr_scheduler: str = <span class="string">'exp'</span>  <span class="comment"># ExponentialLR vs CosineAnnealingWarmRestarts</span></span><br><span class="line">    fp16: bool = <span class="literal">False</span>  <span class="comment"># Enable train on FP16</span></span><br><span class="line">    tpu_cores: int = <span class="number">0</span>  <span class="comment"># Enable TPU with 1 core or 8 cores</span></span><br><span class="line"></span><br><span class="line">args = Arg()</span><br></pre></td></tr></table></figure>

<p>ì´ ë¶€ë¶„ê¹Œì§€ëŠ” í¬ê²Œ ë¬¸ì œê°€ ì—†ì–´ë³´ì¸ë‹¤. ë‚˜ë¦„ ì£¼ì„ë„ ê´œì°®ê²Œ ë˜ì—ˆì§€ ì•Šë‚˜? ğŸ¤£</p>
<p>í•˜ì§€ë§Œ ì´ <code>args</code> ëŠ” ì•„ì£¼ ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆë‹¤. ë°”ë¡œ PyTorch Lightningì—ì„œ ì§€ì›í•˜ëŠ” hparams ì†ì„±ì—ì„œ jsonìœ¼ë¡œ serializableí•˜ì§€ ì•Šë‹¤ëŠ” ê²ƒ. ì´ ì ì´ saveëœ ckptì— hparamsê°€ <code>{}</code> ìœ¼ë¡œ ê³µë°±ìœ¼ë¡œ ë¹„ì–´ìˆëŠ” ìƒí™©ì´ ë°œìƒí•œë‹¤.</p>
<h3 id="TO-BE"><a href="#TO-BE" class="headerlink" title="TO-BE"></a>TO-BE</h3><p>JSON Serializableí•˜ê²Œ ë°”ê¾¸ë©´ ëœë‹¤. ì¦‰, Python dictë¡œ ë°”ê¿”ì£¼ì.</p>
<p>(ê·¸ë¦¬ê³  ì“¸ëª¨ì—†ëŠ” ì¸ìë“¤ë„ ì¢€ ì§€ì›Œì£¼ìâ€¦)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">args = &#123;</span><br><span class="line">    <span class="string">'random_seed'</span>: <span class="number">42</span>, <span class="comment"># Random Seed</span></span><br><span class="line">    <span class="string">'pretrained_model'</span>: <span class="string">'beomi/kcbert-base'</span>,  <span class="comment"># Transformers PLM name</span></span><br><span class="line">    <span class="string">'pretrained_tokenizer'</span>: <span class="string">''</span>,  <span class="comment"># Optional, Transformers Tokenizer Name. Overrides `pretrained_model`</span></span><br><span class="line">    <span class="string">'batch_size'</span>: <span class="number">32</span>,</span><br><span class="line">    <span class="string">'lr'</span>: <span class="number">5e-6</span>,  <span class="comment"># Starting Learning Rate</span></span><br><span class="line">    <span class="string">'epochs'</span>: <span class="number">20</span>,  <span class="comment"># Max Epochs</span></span><br><span class="line">    <span class="string">'max_length'</span>: <span class="number">150</span>,  <span class="comment"># Max Length input size</span></span><br><span class="line">    <span class="string">'train_data_path'</span>: <span class="string">"nsmc/ratings_train.txt"</span>,  <span class="comment"># Train Dataset file </span></span><br><span class="line">    <span class="string">'val_data_path'</span>: <span class="string">"nsmc/ratings_test.txt"</span>,  <span class="comment"># Validation Dataset file </span></span><br><span class="line">    <span class="string">'test_mode'</span>: <span class="literal">False</span>,  <span class="comment"># Test Mode enables `fast_dev_run`</span></span><br><span class="line">    <span class="string">'optimizer'</span>: <span class="string">'AdamW'</span>,  <span class="comment"># AdamW vs AdamP</span></span><br><span class="line">    <span class="string">'lr_scheduler'</span>: <span class="string">'exp'</span>,  <span class="comment"># ExponentialLR vs CosineAnnealingWarmRestarts</span></span><br><span class="line">    <span class="string">'fp16'</span>: <span class="literal">True</span>,  <span class="comment"># Enable train on FP16</span></span><br><span class="line">    <span class="string">'tpu_cores'</span>: <span class="number">0</span>,  <span class="comment"># Enable TPU with 1 core or 8 cores</span></span><br><span class="line">    <span class="string">'cpu_workers'</span>: <span class="number">4</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ë¬¼ë¡  ì´ì œëŠ” <code>args.batch_size</code> ë¡œ ì•¡ì„¸ìŠ¤í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. í•˜ì§€ë§Œ ê·¸ ëŒ€ì‹  hparamsë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. </p>
<h3 id="PyTorch-Lightningì˜-hparams"><a href="#PyTorch-Lightningì˜-hparams" class="headerlink" title="PyTorch-Lightningì˜ hparams"></a>PyTorch-Lightningì˜ hparams</h3><p>PyTorch-Lightningì—ì„œì˜ HyperParamsëŠ” ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì„¸íŒ…í•´ ì¤„ ê²½ìš°, ìë™ìœ¼ë¡œ <code>model.harpams</code> ë‚´ì— ì €ì¥ëœë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">ManuallyArgsModel</span><span class="params">(LightningModule)</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, arg1, arg2, arg3)</span>:</span></span><br><span class="line"><span class="meta">... </span>        super().__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="comment"># manually assign arguments</span></span><br><span class="line"><span class="meta">... </span>        self.save_hyperparameters()</span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line"><span class="meta">... </span>        ...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = ManuallyArgsModel(<span class="number">1</span>, <span class="string">'abc'</span>, <span class="number">3.14</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.hparams</span><br><span class="line"><span class="string">"arg1"</span>: <span class="number">1</span></span><br><span class="line"><span class="string">"arg2"</span>: <span class="string">'abc'</span></span><br><span class="line"><span class="string">"arg3"</span>: <span class="number">3.14</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Reference: <a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#save-hyperparameters">https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#save-hyperparameters</a></p>
</blockquote>
<p>í•˜ì§€ë§Œ ëª¨ë“  ê°’ì„ ëª¨ë¸ ì…ë ¥ì— ì§ì ‘ ë„£ì–´ì£¼ëŠ” ê²ƒì€ ìƒë‹¹íˆ ê·€ì°®ë‹¤.</p>
<p>ë”°ë¼ì„œ <code>**kwargs</code> ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ Initializeì— ë„£ì–´ì¤€ ë’¤ <code>self.save_hyperparameters()</code> ë¥¼ ì‹¤í–‰í•´ì£¼ë©´, í•´ë‹¹ ê°’ë“¤ì„ ëª¨ë‘ <code>self.hparams</code> ì—ì„œ  ì•¡ì„¸ìŠ¤ í•  ìˆ˜ ìˆë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(LightningModule)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.save_hyperparameters() <span class="comment"># ì´ ë¶€ë¶„ì—ì„œ self.hparamsì— ìœ„ kwargsê°€ ì €ì¥ëœë‹¤.</span></span><br><span class="line">        </span><br><span class="line">        self.bert = BertForSequenceClassification.from_pretrained(self.hparams.pretrained_model)</span><br><span class="line">        self.tokenizer = BertTokenizer.from_pretrained(</span><br><span class="line">            self.hparams.pretrained_tokenizer</span><br><span class="line">            <span class="keyword">if</span> self.hparams.pretrained_tokenizer</span><br><span class="line">            <span class="keyword">else</span> self.hparams.pretrained_model</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">[... ì¤‘ëµ ...]</span><br><span class="line"></span><br><span class="line">model = Model(**args)</span><br></pre></td></tr></table></figure>

<h2 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h2><h3 id="AS-IS-1"><a href="#AS-IS-1" class="headerlink" title="AS-IS"></a>AS-IS</h3><p>í˜„ì¬ëŠ” <code>validation_epoch_end</code> ë¶€ë¶„ì—ì„œ Tensorboardì— ë¡œê¹…í•  ê°’ë“¤ì„ ì•„ë˜ì™€ ê°™ì´ Dict ì¤‘ <code>log</code> ë¼ëŠ” Keyì˜ valueë¡œ ìƒˆë¡œìš´ dictë¥¼ ì „ë‹¬í•´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ë¡œê¹…ì´ ì´ë£¨ì–´ì§€ê³  ìˆë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation_epoch_end</span><span class="params">(self, outputs)</span>:</span></span><br><span class="line">    loss = torch.tensor(<span class="number">0</span>, dtype=torch.float)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> outputs:</span><br><span class="line">        loss += i[<span class="string">'loss'</span>].cpu().detach()</span><br><span class="line">    _loss = loss / len(outputs)</span><br><span class="line"></span><br><span class="line">    loss = float(_loss)</span><br><span class="line">    y_true = []</span><br><span class="line">    y_pred = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> outputs:</span><br><span class="line">        y_true += i[<span class="string">'y_true'</span>]</span><br><span class="line">        y_pred += i[<span class="string">'y_pred'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Acc, Precision, Recall, F1</span></span><br><span class="line">    metrics = [</span><br><span class="line">        metric(y_true=y_true, y_pred=y_pred)</span><br><span class="line">        <span class="keyword">for</span> metric <span class="keyword">in</span></span><br><span class="line">        (accuracy_score, precision_score, recall_score, f1_score)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    tensorboard_logs = &#123;</span><br><span class="line">        <span class="string">'val_loss'</span>: loss,</span><br><span class="line">        <span class="string">'val_acc'</span>: metrics[<span class="number">0</span>],</span><br><span class="line">        <span class="string">'val_precision'</span>: metrics[<span class="number">1</span>],</span><br><span class="line">        <span class="string">'val_recall'</span>: metrics[<span class="number">2</span>],</span><br><span class="line">        <span class="string">'val_f1'</span>: metrics[<span class="number">3</span>],</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    print()</span><br><span class="line">    pprint(tensorboard_logs)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'loss'</span>: _loss, <span class="string">'log'</span>: tensorboard_logs&#125;</span><br></pre></td></tr></table></figure>

<p>í•˜ì§€ë§Œ í˜„ì¬ì˜ ë°©ì‹ì€, ì•„ë˜ì™€ ê°™ì´ PyTorch-Lightning  <code>v0.9.1</code> ì—ì„œ Deprecated ë˜ì—ˆê³  <code>v1.0.0</code> ì— Remove ë  ê²ƒì´ë¼ê³  í•œë‹¤.</p>
<p>(ì‹¤ì œë¡œ <code>1.0.0</code> ë²„ì „ì—ì„œ ì‚¬ë¼ì§€ì§€ëŠ” ì•Šì•˜ê³ , ì—¬ì „íˆ ì§€ì›í•˜ê³  ìˆê¸°ëŠ” í•˜ë‹¤.)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The &#123;<span class="built_in">log</span>:dict keyword&#125; was deprecated <span class="keyword">in</span> 0.9.1 and will be removed <span class="keyword">in</span> 1.0.0</span><br><span class="line">Please use self.log(...) inside the lightningModule instead.</span><br><span class="line"><span class="comment"># log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)</span></span><br><span class="line">self.log(<span class="string">'train_loss'</span>, loss, on_step=True, on_epoch=True, prog_bar=True)</span><br><span class="line">  warnings.warn(*args, **kwargs)</span><br></pre></td></tr></table></figure>

<h3 id="TO-BE-1"><a href="#TO-BE-1" class="headerlink" title="TO-BE"></a>TO-BE</h3><p>ë”°ë¼ì„œ ìœ„ì—ì„œ ì œê³µí•˜ëŠ” ê²ƒê³¼ ê°™ì´ <code>self.log()</code> ê¸°ëŠ¥ì„ ì´ìš©í•´ì•¼ í•œë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.log(<span class="string">'train_loss'</span>, loss, on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>ì‹¤ì œ ì½”ë“œë¡œ ë³€ê²½í•œ ê²ƒì€ ì•„ë˜ ì¤‘ë³µì½”ë“œ ì œê±°ì™€ í•¨ê»˜ ì§„í–‰í•´ë³´ì•˜ë‹¤.</p>
<h2 id="ì¤‘ë³µë˜ëŠ”-ì½”ë“œ-ì œê±°í•˜ê¸°"><a href="#ì¤‘ë³µë˜ëŠ”-ì½”ë“œ-ì œê±°í•˜ê¸°" class="headerlink" title="ì¤‘ë³µë˜ëŠ” ì½”ë“œ ì œê±°í•˜ê¸°"></a>ì¤‘ë³µë˜ëŠ” ì½”ë“œ ì œê±°í•˜ê¸°</h2><h3 id="AS-IS-2"><a href="#AS-IS-2" class="headerlink" title="AS-IS"></a>AS-IS</h3><p>ê¸°ì¡´ì˜ ì½”ë“œëŠ” <code>training_step</code>, <code>validation_step</code>, <code>validation_epoch_end</code> ì„¸ ê°€ì§€ë¡œ ìª¼ê°œì ¸ìˆëŠ”ë°, ì‹¤ì œë¡œëŠ” step ë¶€ë¶„ì´ ì™„ì „íˆ ë™ì¼í•˜ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ì¤‘ë³µìœ¼ë¡œ ì‘ì„±í•  ì´ìœ ê°€ ì „í˜€ ì—†ë‹¤.</p>
<p>ë˜í•œ, training stepì—ì„œ train lossë“±ì„ ì¶œë ¥í•˜ë©´, Train datasetì— ëŒ€í•´ ì „ì²´ì ì¸ metricì´ ë‚˜ì˜¤ëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì œê±°í•˜ëŠ” ê²ƒì´ ë‚˜ì•˜ë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span><span class="params">(self, batch, batch_idx)</span>:</span></span><br><span class="line">    data, labels = batch</span><br><span class="line">    output = self(input_ids=data, labels=labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transformers 4.0.0+</span></span><br><span class="line">    loss = output.loss</span><br><span class="line">    logits = output.logits</span><br><span class="line">    </span><br><span class="line">    preds = logits.argmax(dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    y_true = labels.cpu().numpy()</span><br><span class="line">    y_pred = preds.cpu().numpy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Acc, Precision, Recall, F1</span></span><br><span class="line">    metrics = [</span><br><span class="line">        metric(y_true=y_true, y_pred=y_pred)</span><br><span class="line">        <span class="keyword">for</span> metric <span class="keyword">in</span></span><br><span class="line">        (accuracy_score, precision_score, recall_score, f1_score)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    tensorboard_logs = &#123;</span><br><span class="line">        <span class="string">'train_loss'</span>: loss.cpu().detach().numpy().tolist(),</span><br><span class="line">        <span class="string">'train_acc'</span>: metrics[<span class="number">0</span>],</span><br><span class="line">        <span class="string">'train_precision'</span>: metrics[<span class="number">1</span>],</span><br><span class="line">        <span class="string">'train_recall'</span>: metrics[<span class="number">2</span>],</span><br><span class="line">        <span class="string">'train_f1'</span>: metrics[<span class="number">3</span>],</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (batch_idx % self.args.report_cycle) == <span class="number">0</span>:</span><br><span class="line">        print()</span><br><span class="line">        pprint(tensorboard_logs)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'loss'</span>: loss, <span class="string">'log'</span>: tensorboard_logs&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation_step</span><span class="params">(self, batch, batch_idx)</span>:</span></span><br><span class="line">    data, labels = batch</span><br><span class="line">    output = self(input_ids=data, labels=labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transformers 4.0.0+</span></span><br><span class="line">    loss = output.loss</span><br><span class="line">    logits = output.logits</span><br><span class="line"></span><br><span class="line">    preds = logits.argmax(dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    y_true = list(labels.cpu().numpy())</span><br><span class="line">    y_pred = list(preds.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">'loss'</span>: loss,</span><br><span class="line">        <span class="string">'y_true'</span>: y_true,</span><br><span class="line">        <span class="string">'y_pred'</span>: y_pred,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="TO-BE-2"><a href="#TO-BE-2" class="headerlink" title="TO-BE"></a>TO-BE</h3><p>ë”°ë¼ì„œ ì•„ë˜ì™€ ê°™ì´ ê³µí†µí•¨ìˆ˜ <code>step</code> ì„ ë§Œë“¤ì–´ì„œ <code>training_step</code> ê³¼ <code>validation_step</code> ê°ê°ì— ëŒ€í•´ ë™ì¼í•˜ê²Œ ê°’ì„ returní•˜ë„ë¡ ë§Œë“¤ì–´ì£¼ë©´ ëœë‹¤.</p>
<p>ë˜í•œ step ë‚´ì—ì„œ loggingì„ í•˜ëŠ” ê²ƒì„ ì œê±°í•´ì¤€ë‹¤.</p>
<p>ê·¸ë¦¬ê³  í•´ë‹¹ Loggingì„ ê° epoch endì—ì„œ ì²˜ë¦¬í•´ì£¼ê¸° ìœ„í•´ </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, batch, batch_idx)</span>:</span></span><br><span class="line">    data, labels = batch</span><br><span class="line">    output = self(input_ids=data, labels=labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transformers 4.0.0+</span></span><br><span class="line">    loss = output.loss</span><br><span class="line">    logits = output.logits</span><br><span class="line"></span><br><span class="line">    preds = logits.argmax(dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    y_true = list(labels.cpu().numpy())</span><br><span class="line">    y_pred = list(preds.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">'loss'</span>: loss,</span><br><span class="line">        <span class="string">'y_true'</span>: y_true,</span><br><span class="line">        <span class="string">'y_pred'</span>: y_pred,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span><span class="params">(self, batch, batch_idx)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.step(batch, batch_idx)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation_step</span><span class="params">(self, batch, batch_idx)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.step(batch, batch_idx)</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">epoch_end</span><span class="params">(self, outputs, state=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">    loss = torch.tensor(<span class="number">0</span>, dtype=torch.float)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> outputs:</span><br><span class="line">        loss += i[<span class="string">'loss'</span>].cpu().detach()</span><br><span class="line">    loss = loss / len(outputs)</span><br><span class="line"></span><br><span class="line">    y_true = []</span><br><span class="line">    y_pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> outputs:</span><br><span class="line">        y_true += i[<span class="string">'y_true'</span>]</span><br><span class="line">        y_pred += i[<span class="string">'y_pred'</span>]</span><br><span class="line">        </span><br><span class="line">    self.log(state+<span class="string">'_loss'</span>, float(loss), on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>)</span><br><span class="line">    self.log(state+<span class="string">'_acc'</span>, accuracy_score(y_true, y_pred), on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>)</span><br><span class="line">    self.log(state+<span class="string">'_precision'</span>, precision_score(y_true, y_pred), on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>)</span><br><span class="line">    self.log(state+<span class="string">'_recall'</span>, recall_score(y_true, y_pred), on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>)</span><br><span class="line">    self.log(state+<span class="string">'_f1'</span>, f1_score(y_true, y_pred), on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'loss'</span>: loss&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch_end</span><span class="params">(self, outputs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.epoch_end(outputs, state=<span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validation_epoch_end</span><span class="params">(self, outputs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.epoch_end(outputs, state=<span class="string">'val'</span>)</span><br></pre></td></tr></table></figure>



<h2 id="DataLoader-ì½”ë“œ-ì¤‘ë³µ-ì œê±°"><a href="#DataLoader-ì½”ë“œ-ì¤‘ë³µ-ì œê±°" class="headerlink" title="DataLoader ì½”ë“œ ì¤‘ë³µ ì œê±°"></a>DataLoader ì½”ë“œ ì¤‘ë³µ ì œê±°</h2><h3 id="AS-IS-3"><a href="#AS-IS-3" class="headerlink" title="AS-IS"></a>AS-IS</h3><p>DataLoaderë¥¼ ì»¤ìŠ¤í…€ìœ¼ë¡œ ì •ì˜í•  ë•Œ <code>path</code>, <code>shuffle</code> ì„¤ì •ì„ ì œì™¸í•˜ê³ ì„œëŠ” ëª¨ë‘ ë™ì¼í•œ ì½”ë“œë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_dataloader</span><span class="params">(self)</span>:</span></span><br><span class="line">    df = self.read_data(self.args.train_data_path)</span><br><span class="line">    df = self.preprocess_dataframe(df)</span><br><span class="line"></span><br><span class="line">    dataset = TensorDataset(</span><br><span class="line">        torch.tensor(df[<span class="string">'document'</span>].to_list(), dtype=torch.long),</span><br><span class="line">        torch.tensor(df[<span class="string">'label'</span>].to_list(), dtype=torch.long),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> DataLoader(</span><br><span class="line">        dataset,</span><br><span class="line">        batch_size=self.args.batch_size <span class="keyword">or</span> self.batch_size,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=self.args.cpu_workers,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val_dataloader</span><span class="params">(self)</span>:</span></span><br><span class="line">    df = self.read_data(self.args.val_data_path)</span><br><span class="line">    df = self.preprocess_dataframe(df)</span><br><span class="line"></span><br><span class="line">    dataset = TensorDataset(</span><br><span class="line">        torch.tensor(df[<span class="string">'document'</span>].to_list(), dtype=torch.long),</span><br><span class="line">        torch.tensor(df[<span class="string">'label'</span>].to_list(), dtype=torch.long),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> DataLoader(</span><br><span class="line">        dataset,</span><br><span class="line">        batch_size=self.args.batch_size <span class="keyword">or</span> self.batch_size,</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        num_workers=self.args.cpu_workers,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h3 id="TO-BE-3"><a href="#TO-BE-3" class="headerlink" title="TO-BE"></a>TO-BE</h3><p>ë”°ë¼ì„œ ì•„ë˜ì™€ ê°™ì´ <code>dataloader</code> ê³µìš© í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ì •ë¦¬ë¥¼ í•´ì£¼ì—ˆë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataloader</span><span class="params">(self, path, shuffle=False)</span>:</span></span><br><span class="line">    df = self.read_data(path)</span><br><span class="line">    df = self.preprocess_dataframe(df)</span><br><span class="line"></span><br><span class="line">    dataset = TensorDataset(</span><br><span class="line">        torch.tensor(df[<span class="string">'document'</span>].to_list(), dtype=torch.long),</span><br><span class="line">        torch.tensor(df[<span class="string">'label'</span>].to_list(), dtype=torch.long),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> DataLoader(</span><br><span class="line">        dataset,</span><br><span class="line">        batch_size=self.hparams.batch_size <span class="keyword">or</span> self.batch_size,</span><br><span class="line">        shuffle=shuffle,</span><br><span class="line">        num_workers=self.hparams.cpu_workers,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_dataloader</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.dataloader(self.hparams.train_data_path, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val_dataloader</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.dataloader(self.hparams.val_data_path, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>





<h2 id="Model-CKPT-Callback"><a href="#Model-CKPT-Callback" class="headerlink" title="Model CKPT Callback"></a>Model CKPT Callback</h2><h3 id="AS-IS-4"><a href="#AS-IS-4" class="headerlink" title="AS-IS"></a>AS-IS</h3><p>í˜„ì¬ëŠ” ì‘ì—…í´ë”(ipynb ìˆëŠ” ê³³) ë‚´ì˜ <code>./lightning_logs/version_5</code> í˜•ì‹ê³¼ ê°™ì€ í´ë”ì— Tensorboardí˜•ì‹ì˜ ë¡œê·¸, ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ stepì˜ ì²´í¬í¬ì¸íŠ¸ê°€ ì €ì¥ëœë‹¤.</p>
<p>í•˜ì§€ë§Œ ë§ˆì§€ë§‰ stepì´ ì•„ë‹Œ, loggingì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì—¬ëŸ¬ ê°’(<code>val_acc</code> ë“±)ì„ ëª¨ë‹ˆí„°ë§í•˜ë©° <strong>ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸</strong>ì„ ì°¾ê¸° ìœ„í•´ì„œëŠ” ì¶”ê°€ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤.</p>
<h3 id="TO-BE-4"><a href="#TO-BE-4" class="headerlink" title="TO-BE"></a>TO-BE</h3><p>ì•„ë˜ì™€ ê°™ì´ <code>ModelCheckpoint</code> ì½œë°±ì„ ì‚¬ìš©í•´ ì•„ë˜ì™€ ê°™ì´ ì–´ë–¤ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ, ì–´ë–¤ Metricì„ ëª¨ë‹ˆí„°ë§í• ì§€, ëª‡ ê°œì˜ íŒŒì¼ì„ ì €ì¥í• ì§€ ì§€ì •í•´ì£¼ë©´ ê²°ê³¼ê°’ê³¼ í•¨ê»˜ ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ìˆë‹¤.</p>
<p>ì•„ë˜ ì½”ë“œì—ì„œëŠ” epoch, val_acc ê¸°ì¤€ ì†Œìˆ˜ì  ì•„ë˜ 4ìë¦¬ê¹Œì§€ ê¸°ë¡í•´ ì €ì¥í•œë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line">checkpoint_callback = ModelCheckpoint(</span><br><span class="line">    filename=<span class="string">'epoch&#123;epoch&#125;-val_acc&#123;val_acc:.4f&#125;'</span>,</span><br><span class="line">    monitor=<span class="string">'val_acc'</span>,</span><br><span class="line">    save_top_k=<span class="number">3</span>,</span><br><span class="line">    mode=<span class="string">'max'</span>,</span><br><span class="line">    auto_insert_metric_name=<span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    callbacks=[checkpoint_callback],</span><br><span class="line">    ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>NOTE</strong>: ê¸€ ì‘ì„± ì‹œê¸°ì¸ 2021.03.16 ê¸°ì¤€ <code>pytorch-lightning</code>ì˜ Stableë²„ì „ì´ <code>v1.2.3</code>ìœ¼ë¡œ, <code>auto_insert_metric_name</code> ì˜µì…˜ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ Colab codeì—ì„œëŠ” master branchë¥¼ ë°›ì•„ ì„¤ì¹˜í•©ë‹ˆë‹¤.</p>
</blockquote>
<h2 id="Main-Function-for-DDP-ìˆ˜ì •"><a href="#Main-Function-for-DDP-ìˆ˜ì •" class="headerlink" title="Main Function (for DDP) ìˆ˜ì •"></a>Main Function (for DDP) ìˆ˜ì •</h2><h3 id="AS-IS-5"><a href="#AS-IS-5" class="headerlink" title="AS-IS"></a>AS-IS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Using PyTorch Ver"</span>, torch.__version__)</span><br><span class="line">    print(<span class="string">"Fix Seed:"</span>, args.random_seed)</span><br><span class="line">    seed_everything(args.random_seed)</span><br><span class="line">    model = Model(args)</span><br></pre></td></tr></table></figure>

<h3 id="TO-BE-5"><a href="#TO-BE-5" class="headerlink" title="TO-BE"></a>TO-BE</h3><p>ìœ„ì—ì„œ ì‚¬ìš©í•œ <code>args</code> ì¸ìì— attributeë¡œ ì•¡ì„¸ìŠ¤ í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— ì•„ë˜ì²˜ëŸ¼ ì „ë‹¬í•´ì¤˜ì•¼ í•œë‹¤.</p>
<p>ë˜í•œ, Model Init ì¸ìì— Dictë¥¼ <code>kwargs</code> í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•´ì£¼ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ dicì„ unpackingí•´ì„œ ì „ë‹¬í•´ì¤€ë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Using PyTorch Ver"</span>, torch.__version__)</span><br><span class="line">    print(<span class="string">"Fix Seed:"</span>, args[<span class="string">'random_seed'</span>])</span><br><span class="line">    seed_everything(args[<span class="string">'random_seed'</span>])</span><br><span class="line">    model = Model(**args)</span><br></pre></td></tr></table></figure>

<h2 id="ë§ºìœ¼ë©°"><a href="#ë§ºìœ¼ë©°" class="headerlink" title="ë§ºìœ¼ë©°"></a>ë§ºìœ¼ë©°</h2><p>ì´ì „ ê²Œì‹œê¸€, <a href="/2020/12/04/Transformers4/">BertForSequenceClassification on Transformers v4.0.0</a>ì„ ë§ºìœ¼ë©° ë§í•œ ê²ƒê³¼ ë™ì¼í•˜ê²Œ ë§ˆë¬´ë¦¬í•œë‹¤.</p>
<blockquote>
<blockquote>
<p>â€œì˜ ëŒì•„ê°€ëŠ” ì½”ë“œëŠ” ê±´ë“œë¦¬ëŠ”ê²Œ ì•„ë‹ˆì§€ë§Œ, ì½”ë“œëŠ” ê°€ë§Œ ë‚´ë¹„ë‘ë©´ ì©ëŠ”ë‹¤.â€</p>
</blockquote>
</blockquote>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/bert/" rel="tag">bert</a>, <a class="has-link-grey -link" href="/tags/finetune/" rel="tag">finetune</a>, <a class="has-link-grey -link" href="/tags/huggingface/" rel="tag">huggingface</a>, <a class="has-link-grey -link" href="/tags/kcbert/" rel="tag">kcbert</a>, <a class="has-link-grey -link" href="/tags/transformers/" rel="tag">transformers</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2021/03/15/KcBERT-MLM-Finetune/">
                <span class="level-item">KcBERT MLM Finetuneìœ¼ë¡œ Domain adaptationí•˜ê¸°</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right ">
    
        

    <div class="card widget" id="toc">
        <div class="card-content">
            <div class="menu">
                <h3 class="menu-label">
                    ì¹´íƒˆë¡œê·¸
                </h3>
                <ul class="menu-list"><li>
        <a class="is-flex" href="#ë“¤ì–´ê°€ë©°">
        <span class="has-mr-6">1</span>
        <span>ë“¤ì–´ê°€ë©°</span>
        </a></li><li>
        <a class="is-flex" href="#Args-Hparams">
        <span class="has-mr-6">2</span>
        <span>Args? Hparams?</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AS-IS">
        <span class="has-mr-6">2.1</span>
        <span>AS-IS</span>
        </a></li><li>
        <a class="is-flex" href="#TO-BE">
        <span class="has-mr-6">2.2</span>
        <span>TO-BE</span>
        </a></li><li>
        <a class="is-flex" href="#PyTorch-Lightningì˜-hparams">
        <span class="has-mr-6">2.3</span>
        <span>PyTorch-Lightningì˜ hparams</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Logging">
        <span class="has-mr-6">3</span>
        <span>Logging</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AS-IS-1">
        <span class="has-mr-6">3.1</span>
        <span>AS-IS</span>
        </a></li><li>
        <a class="is-flex" href="#TO-BE-1">
        <span class="has-mr-6">3.2</span>
        <span>TO-BE</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#ì¤‘ë³µë˜ëŠ”-ì½”ë“œ-ì œê±°í•˜ê¸°">
        <span class="has-mr-6">4</span>
        <span>ì¤‘ë³µë˜ëŠ” ì½”ë“œ ì œê±°í•˜ê¸°</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AS-IS-2">
        <span class="has-mr-6">4.1</span>
        <span>AS-IS</span>
        </a></li><li>
        <a class="is-flex" href="#TO-BE-2">
        <span class="has-mr-6">4.2</span>
        <span>TO-BE</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#DataLoader-ì½”ë“œ-ì¤‘ë³µ-ì œê±°">
        <span class="has-mr-6">5</span>
        <span>DataLoader ì½”ë“œ ì¤‘ë³µ ì œê±°</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AS-IS-3">
        <span class="has-mr-6">5.1</span>
        <span>AS-IS</span>
        </a></li><li>
        <a class="is-flex" href="#TO-BE-3">
        <span class="has-mr-6">5.2</span>
        <span>TO-BE</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Model-CKPT-Callback">
        <span class="has-mr-6">6</span>
        <span>Model CKPT Callback</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AS-IS-4">
        <span class="has-mr-6">6.1</span>
        <span>AS-IS</span>
        </a></li><li>
        <a class="is-flex" href="#TO-BE-4">
        <span class="has-mr-6">6.2</span>
        <span>TO-BE</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Main-Function-for-DDP-ìˆ˜ì •">
        <span class="has-mr-6">7</span>
        <span>Main Function (for DDP) ìˆ˜ì •</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AS-IS-5">
        <span class="has-mr-6">7.1</span>
        <span>AS-IS</span>
        </a></li><li>
        <a class="is-flex" href="#TO-BE-5">
        <span class="has-mr-6">7.2</span>
        <span>TO-BE</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#ë§ºìœ¼ë©°">
        <span class="has-mr-6">8</span>
        <span>ë§ºìœ¼ë©°</span>
        </a></li></ul>
            </div>
        </div>
    </div>

    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    Beomi&#39;s Tech Blog
                
                </a>
                <p class="is-size-7">
                &copy; 2021 Junbum Lee&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("ko");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://beomi.github.io',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Kembali ke atas" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>








<script src="/js/main.js" defer></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
</body>
</html>